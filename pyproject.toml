[tool.poetry]
name = "llm-inference"
version = "0.2.0"
description = "An inference server for Bloomz Large Language Models (LLMs)"
authors = ["Killian Mah√© <killianmahe.pro@gmail.com>"]
license = "Apache-2.0"
repository = "https://github.com/CreditMutuelArkea/llm-inference"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.10"
transformers = "^4.45.1"
fastapi = "^0.115.0"
uvicorn = "^0.31.0"
torch = "^2.0.1"
pydantic = "^2.9.2"
prometheus-client = "^0.21.0"
httpx = "^0.27.2"
numpy = "^2.1.1"

[tool.poetry.group.test.dependencies]
pytest = "^8.3.3"
requests-mock = "^1.12.1"


[tool.poetry.group.dev.dependencies]
black = "^24.8.0"
pylint = "^3.3.1"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

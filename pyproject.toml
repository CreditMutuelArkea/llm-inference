[tool.poetry]
name = "llm-inference"
version = "0.3.0"
description = "An inference server for Bloomz Large Language Models (LLMs)"
authors = ["Killian Mah√© <killianmahe.pro@gmail.com>"]
license = "Apache-2.0"
repository = "https://github.com/CreditMutuelArkea/llm-inference"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.10"
transformers = "^4.52.4"
fastapi = "^0.115.0"
uvicorn = "^0.34.3"
torch = "^2.7.1"
pydantic = "^2.11.5"
prometheus-client = "^0.22.1"
httpx = "^0.28.1"
numpy = "^2.2.6"
starlette = "^0.46.0"
jinja2 = "^3.1.6"
h11 = "^0.16.0"

[tool.poetry.group.test.dependencies]
pytest = "^8.3.3"
requests-mock = "^1.12.1"


[tool.poetry.group.dev.dependencies]
black = "^24.8.0"
pylint = "^3.3.1"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
